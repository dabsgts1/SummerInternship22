{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5717351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/diyabansal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/diyabansal/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/diyabansal/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/diyabansal/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# using spacy to implement NER to identify entities in report\n",
    "import os\n",
    "import spacy\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from pikepdf import Pdf\n",
    "from spacy import displacy\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import textrazor\n",
    "\n",
    "textrazor.api_key = '706537941648c9e8d8c9e99fba2bc0119d8150883b38ceb21b04c2fd'\n",
    "# db688@cornell.edu: '706537941648c9e8d8c9e99fba2bc0119d8150883b38ceb21b04c2fd'\n",
    "# diyabansal2002@gmail.com: '5b9f3f80983ef72fc69768f28a97225b44c17b7669d954ab41eab2c3'\n",
    "client = textrazor.TextRazor(extractors=[\"entities\", \"topics\"])\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8985fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETURNS A LIST OF STRINGS WITH RANGE OF PAGE NUMBERS TO BE PARSED THROUGH\n",
    "\n",
    "def pages_list(start, end):\n",
    "    pages = []\n",
    "    current = start\n",
    "    \n",
    "    while (current <= end):\n",
    "        page = '<Page:' + str(current) + '>'\n",
    "        pages.append(page)\n",
    "        current = current + 1\n",
    "        \n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ba4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERTS CID ENCODED WORDS TO CHARACTERS\n",
    "\n",
    "def replace_cid_space(text_str):\n",
    "    while ('cid' in text_str.lower()):\n",
    "    \n",
    "        # finding the (cid:XXXX) parts of the strings\n",
    "        starting_index = text_str.index('(cid:')\n",
    "        ending_index = text_str.index(')', starting_index)\n",
    "        cid_word = text_str[starting_index:ending_index+1]\n",
    "    \n",
    "        # replacing (cid:XXXX) with ''\n",
    "        text_str = text_str.replace(cid_word, '')\n",
    "    \n",
    "    return text_str\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17e28da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply word tokenization and part-of-speech tagging to the sentence\n",
    "\n",
    "def preprocess_nltk(sen):\n",
    "    sen = nltk.word_tokenize(sen)\n",
    "    sen = nltk.pos_tag(sen)\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "504947c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if parameter string has anything other than 'nan', spaces, and commas\n",
    "# returns a boolean\n",
    "\n",
    "def contains_nan(str):\n",
    "    str = str.replace('nan', '')\n",
    "    str = str.replace(' ', '')\n",
    "    str = str.replace(',', '')\n",
    "    if (str == ''):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31dcd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a string replacing all spaces and occurences of the word 'nan'\n",
    "\n",
    "def remove_nan(str):\n",
    "    str = str.replace('nan', '')\n",
    "    str = str.replace(' ', '')\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6122051d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter range of pages: starting page: 18\n",
      "Enter range of pages: ending page: 21\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Entity</th>\n",
       "      <th>SpaCy Label</th>\n",
       "      <th>NLTK Label</th>\n",
       "      <th>TextRazor Label</th>\n",
       "      <th>TextRazor Confidence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>NIIT  Technologies’  comme...</td>\n",
       "      <td>10</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>18  Celebration of 15 years of partnership wit...</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>18  Celebration of 15 years of partnership wit...</td>\n",
       "      <td>15  YEARS</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>WHITELANE RESEARCH</td>\n",
       "      <td>ORG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Year Gone By FY 2019NI...</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>DATE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Year Gone By FY 2019NI...</td>\n",
       "      <td>YEAR GONE BY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Incessant  Technologies  cited  as  a  Strong ...</td>\n",
       "      <td>ZINNOV</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Incessant  Technologies  cited  as  a  Strong ...</td>\n",
       "      <td>ZINNOV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>361 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence              Entity  \\\n",
       "337                       Named  as  a  Leader  in ...                   0   \n",
       "325                       Named  as  a  Leader  in ...                   1   \n",
       "103                      NIIT  Technologies’  comme...                  10   \n",
       "159  18  Celebration of 15 years of partnership wit...                  15   \n",
       "158  18  Celebration of 15 years of partnership wit...           15  YEARS   \n",
       "..                                                 ...                 ...   \n",
       "329                       Named  as  a  Leader  in ...  WHITELANE RESEARCH   \n",
       "3                        The Year Gone By FY 2019NI...                YEAR   \n",
       "5                        The Year Gone By FY 2019NI...        YEAR GONE BY   \n",
       "306  Incessant  Technologies  cited  as  a  Strong ...              ZINNOV   \n",
       "320  Incessant  Technologies  cited  as  a  Strong ...              ZINNOV   \n",
       "\n",
       "    SpaCy Label    NLTK Label TextRazor Label TextRazor Confidence Score  \n",
       "337    CARDINAL           NaN             NaN                        NaN  \n",
       "325       MONEY           NaN             NaN                        NaN  \n",
       "103    CARDINAL           NaN             NaN                        NaN  \n",
       "159         NaN           NaN             NaN                        NaN  \n",
       "158        DATE           NaN             NaN                        NaN  \n",
       "..          ...           ...             ...                        ...  \n",
       "329         ORG           NaN             NaN                        NaN  \n",
       "3          DATE           NaN             NaN                        NaN  \n",
       "5           NaN  ORGANIZATION             NaN                        NaN  \n",
       "306      PERSON           NaN             NaN                        NaN  \n",
       "320         NaN        PERSON             NaN                        NaN  \n",
       "\n",
       "[361 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = 0    # Distance of left side of character from left side of page.\n",
    "x1 = 0.5  # Distance of right side of character from left side of page.\n",
    "y0 = 0    # Distance of bottom of character from bottom of page.\n",
    "y1 = 1    # Distance of top of character from bottom of page.\n",
    "\n",
    "all_content = []\n",
    "start = int(input('Enter range of pages: starting page: '))\n",
    "end = int(input('Enter range of pages: ending page: '))\n",
    "print()\n",
    "pages = pages_list(start, end)\n",
    "\n",
    "df = pd.DataFrame(columns=['Sentence','Entity', 'SpaCy Label', 'NLTK Label', 'TextRazor Label', 'TextRazor Confidence Score'])\n",
    "\n",
    "with pdfplumber.open(\"annual-report-2019.pdf\") as pdf:\n",
    "    \n",
    "    # for each page\n",
    "    for i, page in enumerate(pdf.pages): \n",
    "        \n",
    "        if (str(page) in pages):\n",
    "            width = page.width\n",
    "            height = page.height\n",
    "\n",
    "            # Crop page\n",
    "            left_bbox = (x0*float(width), y0*float(height), x1*float(width), y1*float(height))\n",
    "            page_crop = page.crop(bbox=left_bbox)\n",
    "            left_text = page_crop.extract_text()\n",
    "\n",
    "            left_bbox = (0.5*float(width), y0*float(height), 1*float(width), y1*float(height))\n",
    "            page_crop = page.crop(bbox=left_bbox)\n",
    "            right_text = page_crop.extract_text()\n",
    "        \n",
    "            page_context = ' '.join([left_text, right_text])\n",
    "            all_content.append(page_context)\n",
    "\n",
    "            # text1= NER(replace_cid_space(page_context))\n",
    "            # sentences = list(text1.sents)\n",
    "            \n",
    "            # for each sentence in all sentences on a page\n",
    "            \n",
    "            # for sentence in sentences:\n",
    "            for sentence in nltk.sent_tokenize(replace_cid_space(page_context)):\n",
    "                \n",
    "                # using SPACY\n",
    "                text2 = NER(str(sentence))\n",
    "                \n",
    "                # removing '\\n' from each sentence\n",
    "                sen = str(sentence)\n",
    "                sen = sen.replace('\\n','')\n",
    "                \n",
    "                # parsing through each word\n",
    "                for word in text2.ents:\n",
    "                    newrow = pd.DataFrame({'Sentence': [sen], 'Entity':[word.text.upper()], 'SpaCy Label':[word.label_]}, columns=['Sentence','Entity', 'SpaCy Label', 'NLTK Label', 'TextRazor Label', 'TextRazor Confidence Score'])\n",
    "                    df = pd.concat([df, newrow], ignore_index = True)\n",
    "                    \n",
    "                # using NLTK\n",
    "                for sent in nltk.sent_tokenize(sen):\n",
    "                    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "                        if hasattr(chunk, 'label'):\n",
    "                            nltk_label = chunk.label()\n",
    "                            nltk_entity = ' '.join(c[0] for c in chunk)\n",
    "                            nltk_entity = nltk_entity.strip()\n",
    "                            row = df.loc[::-1][df['Entity'] == nltk_entity][df['Sentence'] == sen] # finding a row with this entity and sentence\n",
    "                            if (row.empty): # if no row found, creating a new row\n",
    "                                row = pd.DataFrame({'Sentence': [sen], 'Entity':[nltk_entity.upper()], 'NLTK Label':[nltk_label]}, columns=['Sentence','Entity', 'SpaCy Label', 'NLTK Label', 'TextRazor Label', 'TextRazor Confidence Score'])\n",
    "                                df = pd.concat([df, row], ignore_index = True)\n",
    "                            else: # if row found, then appending the row with NLTK label\n",
    "                                for index in row.index:\n",
    "                                    row.loc[index,'NLTK Label'] = nltk_label\n",
    "                                # making changes to original data frame\n",
    "                                df.loc[row.index,:] = row[:]\n",
    "                \n",
    "                # REMOVING DUPLICATES AFTER SPACY & NLTK\n",
    "                df = df.drop_duplicates() # removing duplicates\n",
    "                df = df.drop_duplicates(subset=['Sentence', 'Entity', 'SpaCy Label'], keep = 'first') # removing duplicates with same sentence entities and spacy label\n",
    "                \n",
    "                # USING TEXTRAZOR\n",
    "                response = client.analyze(sen)\n",
    "                entities = list(response.entities())\n",
    "                seen = set()\n",
    "                \n",
    "                for entity in entities:\n",
    "                    if(entity.id not in seen):\n",
    "                        tr_fbt = str(entity.freebase_types)\n",
    "                        tr_cf = float(entity.confidence_score)\n",
    "                        \n",
    "                        if (tr_fbt == '[]'):\n",
    "                            tr_fbt = np.NaN\n",
    "                        if (tr_cf == 0.5):\n",
    "                            tr_cf = np.NaN\n",
    "                        \n",
    "                        row = df.loc[::-1][df['Entity'] == entity.id][df['Sentence'] == sen] # finding a row with this entity and sentence\n",
    "                        # print(row)\n",
    "                        \n",
    "                        if (row.empty): # if no row found, creating a new row\n",
    "                            row = pd.DataFrame({'Sentence': [sen], 'Entity':[entity.id.upper()], 'TextRazor Label':[tr_fbt], 'TextRazor Confidence Score':[tr_cf]}, columns=['Sentence','Entity', 'SpaCy Label', 'NLTK Label', 'TextRazor Label', 'TextRazor Confidence Score'])\n",
    "                            # print(row)\n",
    "                            df = pd.concat([df, row], ignore_index = True)\n",
    "                        else: # if row found, then appending the row with NLTK label\n",
    "                            for index in row.index:\n",
    "                                row.loc[index,'TextRazor Label'] = tr_fbt\n",
    "                                row.loc[index,'TextRazor Confidence Score'] = tr_cf\n",
    "                            # print(row)\n",
    "                            # making changes to original data frame\n",
    "                            df.loc[row.index,:] = row[:]\n",
    "                        seen.add(entity.id)\n",
    "                        \n",
    "                # REMOVING DUPLICATES AFTER TEXTRAZOR\n",
    "                df = df.drop_duplicates() # removing duplicates\n",
    "                # df = df.drop_duplicates(subset=['Sentence', 'Entity', 'SpaCy Label', 'NLTK Label']) # removing duplicates with same sentence entities and spacy nltk column values\n",
    "                \n",
    "            \n",
    "# df = df.groupby(['Sentence','Entity'])\n",
    "# df = df.groupby(['Sentence','Entity'])['SpaCy Label'].apply(','.join).reset_index()\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'], axis=1)\n",
    "df = df.sort_values(by=['Entity'])\n",
    "df\n",
    "\n",
    "# displacy.render(text1,style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "125b60a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a map for SpaCy and NLTK\n",
    "# organized as Spacy and NLTK labels concatenated\n",
    "map_list = ['CARDINAL',\n",
    " 'DATE',\n",
    " 'EVENT',\n",
    " 'FACFACILITY',\n",
    " 'GPEGPE',\n",
    " 'LANGUAGE',\n",
    " 'LAW',\n",
    " 'LOCLOCATION',\n",
    " 'MONEY',\n",
    " 'NORPGSP',\n",
    " 'ORDINAL',\n",
    " 'ORGORGANIZATION',\n",
    " 'PERCENT',\n",
    " 'PERSONPERSON',\n",
    " 'PRODUCT',\n",
    " 'QUANTITY',\n",
    " 'TIME',\n",
    " 'WORK_OF_ART']\n",
    "\n",
    "dict_label = {'CARDINAL': 'CARDINAL', 'DATE': 'DATE', 'EVENT':'EVENT', 'FAC':'FACILITY', 'FACILITY':'FACILITY',\n",
    "              'GPE':'GEO-POLITICAL ENTITY', 'LANGUAGE':'LANGUAGE', 'LAW':'LAW', 'LOC':'LOCATION', 'LOCATION':'LOCATION',\n",
    "             'MONEY':'MONEY', 'NORP':'NATIONAL, RELIGIOUS OR POLITICAL GROUPS', 'GSP':'GEO-SOCIO-POLITICAL ENTITY',\n",
    "             'ORDINAL':'ORDINAL', 'ORG':'ORGANIZATION', 'ORGANIZATION':'ORGANIZATION','PERCENT':'PERCENT', 'PERSON':'PERSON',\n",
    "             'PRODUCT':'PRODUCT', 'QUANTITY':'QUANTITY', 'TIME':'TIME', 'WORK_OF_ART':'WORK OF ART'}\n",
    "\n",
    "# NLTK: FACILITY, GPE, GSP, LOCATION, ORGANIZATION, PERSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "150a59c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Entity</th>\n",
       "      <th>SpaCy Label</th>\n",
       "      <th>NLTK Label</th>\n",
       "      <th>TextRazor Label</th>\n",
       "      <th>TextRazor Confidence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIIT  Technologies’  comme...</td>\n",
       "      <td>10</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18  Celebration of 15 years of partnership wit...</td>\n",
       "      <td>15</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18  Celebration of 15 years of partnership wit...</td>\n",
       "      <td>15  YEARS</td>\n",
       "      <td>DATE</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...</td>\n",
       "      <td>WHISHWORKS</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>['/business/employer'] nan</td>\n",
       "      <td>1.748 nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>WHITELANE RESEARCH</td>\n",
       "      <td>nan nan ORG</td>\n",
       "      <td>ORGANIZATION nan nan</td>\n",
       "      <td>nan ['/organization/organization'] nan</td>\n",
       "      <td>nan nan nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>The Year Gone By FY 2019NI...</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>DATE</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>The Year Gone By FY 2019NI...</td>\n",
       "      <td>YEAR GONE BY</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Incessant  Technologies  cited  as  a  Strong ...</td>\n",
       "      <td>ZINNOV</td>\n",
       "      <td>PERSON nan</td>\n",
       "      <td>nan PERSON</td>\n",
       "      <td>nan nan</td>\n",
       "      <td>nan nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence              Entity  \\\n",
       "0                         Named  as  a  Leader  in ...                   0   \n",
       "1                         Named  as  a  Leader  in ...                   1   \n",
       "2                        NIIT  Technologies’  comme...                  10   \n",
       "3    18  Celebration of 15 years of partnership wit...                  15   \n",
       "4    18  Celebration of 15 years of partnership wit...           15  YEARS   \n",
       "..                                                 ...                 ...   \n",
       "314  Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...          WHISHWORKS   \n",
       "315                       Named  as  a  Leader  in ...  WHITELANE RESEARCH   \n",
       "316                      The Year Gone By FY 2019NI...                YEAR   \n",
       "317                      The Year Gone By FY 2019NI...        YEAR GONE BY   \n",
       "318  Incessant  Technologies  cited  as  a  Strong ...              ZINNOV   \n",
       "\n",
       "     SpaCy Label            NLTK Label  \\\n",
       "0       CARDINAL                   nan   \n",
       "1          MONEY                   nan   \n",
       "2       CARDINAL                   nan   \n",
       "3            nan                   nan   \n",
       "4           DATE                   nan   \n",
       "..           ...                   ...   \n",
       "314      nan ORG      nan ORGANIZATION   \n",
       "315  nan nan ORG  ORGANIZATION nan nan   \n",
       "316         DATE                   nan   \n",
       "317          nan          ORGANIZATION   \n",
       "318   PERSON nan            nan PERSON   \n",
       "\n",
       "                            TextRazor Label TextRazor Confidence Score  \n",
       "0                                       nan                        nan  \n",
       "1                                       nan                        nan  \n",
       "2                                       nan                        nan  \n",
       "3                                       nan                        nan  \n",
       "4                                       nan                        nan  \n",
       "..                                      ...                        ...  \n",
       "314              ['/business/employer'] nan                  1.748 nan  \n",
       "315  nan ['/organization/organization'] nan                nan nan nan  \n",
       "316                                     nan                        nan  \n",
       "317                                     nan                        nan  \n",
       "318                                 nan nan                    nan nan  \n",
       "\n",
       "[319 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_iter = [] # list keeping track of entities we already have parsed through\n",
    "\n",
    "# new dataframe which stores single entity entries without sentences\n",
    "new_df = pd.DataFrame(columns=['Sentence','Entity', 'SpaCy Label', 'NLTK Label', 'TextRazor Label', 'TextRazor Confidence Score'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    ele = row['Sentence'] + row['Entity']\n",
    "    \n",
    "    if (not ele in list_iter):\n",
    "\n",
    "        list_iter.append(ele)\n",
    "        sub = df.loc[(df['Entity'] == row['Entity']) & (df['Sentence'] == row['Sentence'])]\n",
    "\n",
    "        spa = ''\n",
    "        nlt = ''\n",
    "        tl = ''\n",
    "        tc = ''\n",
    "\n",
    "        for index2, row2 in sub.iterrows():\n",
    "\n",
    "            spa2 = row2['SpaCy Label']\n",
    "            nlt2 = row2['NLTK Label']\n",
    "            tl2 = row2['TextRazor Label']\n",
    "            tc2 = row2['TextRazor Confidence Score']\n",
    "\n",
    "            spa = spa + ' ' + str(spa2)\n",
    "            nlt = nlt + ' ' + str(nlt2)\n",
    "            tl = tl + ' ' + str(tl2)\n",
    "            tc = tc + ' ' + str(tc2)\n",
    "\n",
    "        spa = spa[1:]\n",
    "        nlt = nlt[1:]\n",
    "        tl = tl[1:]\n",
    "        tc = tc[1:]\n",
    "\n",
    "        new_row = pd.DataFrame({'Sentence':[row['Sentence']], 'Entity':[row['Entity']], 'SpaCy Label': [spa], 'NLTK Label': [nlt], 'TextRazor Label':[tl], 'TextRazor Confidence Score':[tc]}, columns=['Sentence', 'Entity', 'SpaCy Label', 'NLTK Label', 'TextRazor Label', 'TextRazor Confidence Score'])\n",
    "        new_df = pd.concat([new_df, new_row], ignore_index = True)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3aa45c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Entity</th>\n",
       "      <th>SpaCy Label</th>\n",
       "      <th>NLTK Label</th>\n",
       "      <th>TextRazor Label</th>\n",
       "      <th>TextRazor Confidence Score</th>\n",
       "      <th>Final Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>MONEY</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NIIT  Technologies’  comme...</td>\n",
       "      <td>10</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18  Celebration of 15 years of partnership wit...</td>\n",
       "      <td>15</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18  Celebration of 15 years of partnership wit...</td>\n",
       "      <td>15  YEARS</td>\n",
       "      <td>DATE</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...</td>\n",
       "      <td>WHISHWORKS</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>['/business/employer'] nan</td>\n",
       "      <td>1.748 nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>WHITELANE RESEARCH</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan ['/organization/organization']</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>The Year Gone By FY 2019NI...</td>\n",
       "      <td>YEAR</td>\n",
       "      <td>DATE</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>The Year Gone By FY 2019NI...</td>\n",
       "      <td>YEAR GONE BY</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Incessant  Technologies  cited  as  a  Strong ...</td>\n",
       "      <td>ZINNOV</td>\n",
       "      <td>PERSON nan</td>\n",
       "      <td>nan PERSON</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>319 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence              Entity  \\\n",
       "0                         Named  as  a  Leader  in ...                   0   \n",
       "1                         Named  as  a  Leader  in ...                   1   \n",
       "2                        NIIT  Technologies’  comme...                  10   \n",
       "3    18  Celebration of 15 years of partnership wit...                  15   \n",
       "4    18  Celebration of 15 years of partnership wit...           15  YEARS   \n",
       "..                                                 ...                 ...   \n",
       "314  Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...          WHISHWORKS   \n",
       "315                       Named  as  a  Leader  in ...  WHITELANE RESEARCH   \n",
       "316                      The Year Gone By FY 2019NI...                YEAR   \n",
       "317                      The Year Gone By FY 2019NI...        YEAR GONE BY   \n",
       "318  Incessant  Technologies  cited  as  a  Strong ...              ZINNOV   \n",
       "\n",
       "    SpaCy Label        NLTK Label                     TextRazor Label  \\\n",
       "0      CARDINAL               nan                                 nan   \n",
       "1         MONEY               nan                                 nan   \n",
       "2      CARDINAL               nan                                 nan   \n",
       "3           nan               nan                                 nan   \n",
       "4          DATE               nan                                 nan   \n",
       "..          ...               ...                                 ...   \n",
       "314     nan ORG  nan ORGANIZATION          ['/business/employer'] nan   \n",
       "315     nan ORG  ORGANIZATION nan  nan ['/organization/organization']   \n",
       "316        DATE               nan                                 nan   \n",
       "317         nan      ORGANIZATION                                 nan   \n",
       "318  PERSON nan        nan PERSON                                 nan   \n",
       "\n",
       "    TextRazor Confidence Score   Final Label  \n",
       "0                          nan                \n",
       "1                          nan                \n",
       "2                          nan                \n",
       "3                          nan                \n",
       "4                          nan                \n",
       "..                         ...           ...  \n",
       "314                  1.748 nan  ORGANIZATION  \n",
       "315                        nan  ORGANIZATION  \n",
       "316                        nan                \n",
       "317                        nan                \n",
       "318                        nan        PERSON  \n",
       "\n",
       "[319 rows x 7 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if any 2 labels match, identified as true\n",
    "\n",
    "final_df = pd.DataFrame(columns=['Sentence', 'Entity', 'SpaCy Label', 'NLTK Label', 'TextRazor Label', 'TextRazor Confidence Score', 'Final Label'])\n",
    "for index, row in new_df.iterrows():\n",
    "    \n",
    "    final_label = ''\n",
    "    \n",
    "    # removing duplicate words\n",
    "    spa = ' '.join(dict.fromkeys(str(row['SpaCy Label']).split()))\n",
    "    nlt = ' '.join(dict.fromkeys(str(row['NLTK Label']).split()))\n",
    "    tr = ' '.join(dict.fromkeys(str(row['TextRazor Label']).split()))\n",
    "    tc = ' '.join(dict.fromkeys(str(row['TextRazor Confidence Score']).split()))\n",
    "    \n",
    "    # removing nan from string\n",
    "    spa = remove_nan(spa)\n",
    "    nlt = remove_nan(nlt)\n",
    "    tr = remove_nan(tr)\n",
    "    tr = tr.upper()\n",
    "    tc = remove_nan(tc)\n",
    "    \n",
    "    map_compare = spa + nlt\n",
    "    \n",
    "    if ((map_compare in map_list) and (not nlt == '')):\n",
    "        final_label = dict_label[spa]\n",
    "\n",
    "    elif (not spa == ''):\n",
    "        if (dict_label[spa] in tr):\n",
    "            final_label = dict_label[spa]\n",
    "        \n",
    "    elif (not nlt == ''):\n",
    "        if (dict_label[nlt] in tr):\n",
    "            final_label = dict_label[nlt]\n",
    "    \n",
    "    spa = ' '.join(dict.fromkeys(str(row['SpaCy Label']).split()))\n",
    "    nlt = ' '.join(dict.fromkeys(str(row['NLTK Label']).split()))\n",
    "    tr = ' '.join(dict.fromkeys(str(row['TextRazor Label']).split()))\n",
    "    tr = tr.lower()\n",
    "    tc = ' '.join(dict.fromkeys(str(row['TextRazor Confidence Score']).split()))\n",
    "    \n",
    "    final_row = pd.DataFrame({'Sentence':[row['Sentence']], 'Entity':[row['Entity']], 'SpaCy Label': [spa], 'NLTK Label': [nlt], 'TextRazor Label':[tr], 'TextRazor Confidence Score':[tc], 'Final Label': [final_label]}, columns=['Sentence', 'Entity', 'SpaCy Label', 'NLTK Label', 'TextRazor Label', 'TextRazor Confidence Score', 'Final Label'])\n",
    "    final_df = pd.concat([final_df, final_row], ignore_index = True)\n",
    "\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab6e821a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Entity</th>\n",
       "      <th>SpaCy Label</th>\n",
       "      <th>NLTK Label</th>\n",
       "      <th>TextRazor Label</th>\n",
       "      <th>TextRazor Confidence Score</th>\n",
       "      <th>Final Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NIIT  Technologies’  comme...</td>\n",
       "      <td>ADVANTAGEGO</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>19 In this role, Sanjay has been actively supp...</td>\n",
       "      <td>COMMITTEE</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Furthermore, as part of this strategy, your co...</td>\n",
       "      <td>DIGITAL</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...</td>\n",
       "      <td>DIGITAL</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...</td>\n",
       "      <td>DIGITAL INTEGRATION</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Incessant  Technologies  cited  as  a  Strong ...</td>\n",
       "      <td>DIGITAL SERVICES</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>The company also introduced Exact Max to impro...</td>\n",
       "      <td>EXACT MAX</td>\n",
       "      <td>nan PERSON</td>\n",
       "      <td>PERSON nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Sanjay  Mal  appointed  as Sanjay brings over ...</td>\n",
       "      <td>EXECUTIVE</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>During the year, your company:  Collaborated w...</td>\n",
       "      <td>FINANCIAL SERVICES</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>GRANT THORNTON0</td>\n",
       "      <td>nan</td>\n",
       "      <td>PERSON nan</td>\n",
       "      <td>nan ['/people/person']</td>\n",
       "      <td>nan</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Strategic  partnership  with  Blue  Chip Custo...</td>\n",
       "      <td>IBM</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "      <td>['/award/award_winner', '/computer/computer_ma...</td>\n",
       "      <td>10.6</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Strategic  partnership  with  Blue  Chip Custo...</td>\n",
       "      <td>IBM POWER</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>In his current role, he is responsible for dev...</td>\n",
       "      <td>INCESSANT</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Transform at the IntersectAs noted earlier, yo...</td>\n",
       "      <td>INTERSECT</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Cognitive Service Desk Audit, built on Microso...</td>\n",
       "      <td>MICROSOFT AZURE</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>As part of the senior management team, Sanjay ...</td>\n",
       "      <td>NELSONHALL</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>NIIT Technologies supports the client in polic...</td>\n",
       "      <td>NIIT TECHNOLOGIES</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>In order to execute on the company’s strategy ...</td>\n",
       "      <td>NIIT TECHNOLOGIES</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Through these solutions, NIIT Technologies’ cu...</td>\n",
       "      <td>NIIT TECHNOLOGIES</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Ltd) to implement Pega, a business process aut...</td>\n",
       "      <td>PEGA</td>\n",
       "      <td>nan PERSON</td>\n",
       "      <td>PERSON nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Sudhir Singh, CEO, NIIT Technologies with Clie...</td>\n",
       "      <td>RULETEK</td>\n",
       "      <td>ORG nan</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Sudhir Singh, CEO, NIIT Technologies with Clie...</td>\n",
       "      <td>SREEKANTH LAPALA</td>\n",
       "      <td>PERSON nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan ['/people/person']</td>\n",
       "      <td>nan</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Sudhir Singh, CEO, NIIT Technologies with Clie...</td>\n",
       "      <td>SUDHIR SINGH</td>\n",
       "      <td>nan PERSON</td>\n",
       "      <td>nan</td>\n",
       "      <td>['/people/person'] nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...</td>\n",
       "      <td>WHISHWORKS</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>nan ORGANIZATION</td>\n",
       "      <td>['/business/employer'] nan</td>\n",
       "      <td>1.748 nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Named  as  a  Leader  in ...</td>\n",
       "      <td>WHITELANE RESEARCH</td>\n",
       "      <td>nan ORG</td>\n",
       "      <td>ORGANIZATION nan</td>\n",
       "      <td>nan ['/organization/organization']</td>\n",
       "      <td>nan</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Incessant  Technologies  cited  as  a  Strong ...</td>\n",
       "      <td>ZINNOV</td>\n",
       "      <td>PERSON nan</td>\n",
       "      <td>nan PERSON</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence               Entity  \\\n",
       "37                       NIIT  Technologies’  comme...          ADVANTAGEGO   \n",
       "88   19 In this role, Sanjay has been actively supp...            COMMITTEE   \n",
       "102  Furthermore, as part of this strategy, your co...              DIGITAL   \n",
       "103  Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...              DIGITAL   \n",
       "107  Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...  DIGITAL INTEGRATION   \n",
       "109  Incessant  Technologies  cited  as  a  Strong ...     DIGITAL SERVICES   \n",
       "124  The company also introduced Exact Max to impro...            EXACT MAX   \n",
       "125  Sanjay  Mal  appointed  as Sanjay brings over ...            EXECUTIVE   \n",
       "129  During the year, your company:  Collaborated w...   FINANCIAL SERVICES   \n",
       "139                       Named  as  a  Leader  in ...      GRANT THORNTON0   \n",
       "147  Strategic  partnership  with  Blue  Chip Custo...                  IBM   \n",
       "148  Strategic  partnership  with  Blue  Chip Custo...            IBM POWER   \n",
       "152  In his current role, he is responsible for dev...            INCESSANT   \n",
       "174  Transform at the IntersectAs noted earlier, yo...            INTERSECT   \n",
       "194  Cognitive Service Desk Audit, built on Microso...      MICROSOFT AZURE   \n",
       "199  As part of the senior management team, Sanjay ...           NELSONHALL   \n",
       "224  NIIT Technologies supports the client in polic...    NIIT TECHNOLOGIES   \n",
       "228  In order to execute on the company’s strategy ...    NIIT TECHNOLOGIES   \n",
       "232  Through these solutions, NIIT Technologies’ cu...    NIIT TECHNOLOGIES   \n",
       "242  Ltd) to implement Pega, a business process aut...                 PEGA   \n",
       "263  Sudhir Singh, CEO, NIIT Technologies with Clie...              RULETEK   \n",
       "275  Sudhir Singh, CEO, NIIT Technologies with Clie...     SREEKANTH LAPALA   \n",
       "282  Sudhir Singh, CEO, NIIT Technologies with Clie...         SUDHIR SINGH   \n",
       "314  Acquired WHISHWORKS  with  WHISHWORKS,  a  Mul...           WHISHWORKS   \n",
       "315                       Named  as  a  Leader  in ...   WHITELANE RESEARCH   \n",
       "318  Incessant  Technologies  cited  as  a  Strong ...               ZINNOV   \n",
       "\n",
       "    SpaCy Label        NLTK Label  \\\n",
       "37      nan ORG  ORGANIZATION nan   \n",
       "88      ORG nan  nan ORGANIZATION   \n",
       "102     ORG nan  nan ORGANIZATION   \n",
       "103     nan ORG  ORGANIZATION nan   \n",
       "107     nan ORG  ORGANIZATION nan   \n",
       "109     ORG nan  nan ORGANIZATION   \n",
       "124  nan PERSON        PERSON nan   \n",
       "125     ORG nan  nan ORGANIZATION   \n",
       "129     ORG nan  nan ORGANIZATION   \n",
       "139         nan        PERSON nan   \n",
       "147         ORG      ORGANIZATION   \n",
       "148     nan ORG  ORGANIZATION nan   \n",
       "152     ORG nan  nan ORGANIZATION   \n",
       "174     ORG nan  nan ORGANIZATION   \n",
       "194     nan ORG  ORGANIZATION nan   \n",
       "199     nan ORG  ORGANIZATION nan   \n",
       "224     ORG nan  nan ORGANIZATION   \n",
       "228     ORG nan  nan ORGANIZATION   \n",
       "232     nan ORG  ORGANIZATION nan   \n",
       "242  nan PERSON        PERSON nan   \n",
       "263     ORG nan  nan ORGANIZATION   \n",
       "275  PERSON nan               nan   \n",
       "282  nan PERSON               nan   \n",
       "314     nan ORG  nan ORGANIZATION   \n",
       "315     nan ORG  ORGANIZATION nan   \n",
       "318  PERSON nan        nan PERSON   \n",
       "\n",
       "                                       TextRazor Label  \\\n",
       "37                                                 nan   \n",
       "88                                                 nan   \n",
       "102                                                nan   \n",
       "103                                                nan   \n",
       "107                                                nan   \n",
       "109                                                nan   \n",
       "124                                                nan   \n",
       "125                                                nan   \n",
       "129                                                nan   \n",
       "139                             nan ['/people/person']   \n",
       "147  ['/award/award_winner', '/computer/computer_ma...   \n",
       "148                                                nan   \n",
       "152                                                nan   \n",
       "174                                                nan   \n",
       "194                                                nan   \n",
       "199                                                nan   \n",
       "224                                                nan   \n",
       "228                                                nan   \n",
       "232                                                nan   \n",
       "242                                                nan   \n",
       "263                                                nan   \n",
       "275                             nan ['/people/person']   \n",
       "282                             ['/people/person'] nan   \n",
       "314                         ['/business/employer'] nan   \n",
       "315                 nan ['/organization/organization']   \n",
       "318                                                nan   \n",
       "\n",
       "    TextRazor Confidence Score   Final Label  \n",
       "37                         nan  ORGANIZATION  \n",
       "88                         nan  ORGANIZATION  \n",
       "102                        nan  ORGANIZATION  \n",
       "103                        nan  ORGANIZATION  \n",
       "107                        nan  ORGANIZATION  \n",
       "109                        nan  ORGANIZATION  \n",
       "124                        nan        PERSON  \n",
       "125                        nan  ORGANIZATION  \n",
       "129                        nan  ORGANIZATION  \n",
       "139                        nan        PERSON  \n",
       "147                       10.6  ORGANIZATION  \n",
       "148                        nan  ORGANIZATION  \n",
       "152                        nan  ORGANIZATION  \n",
       "174                        nan  ORGANIZATION  \n",
       "194                        nan  ORGANIZATION  \n",
       "199                        nan  ORGANIZATION  \n",
       "224                        nan  ORGANIZATION  \n",
       "228                        nan  ORGANIZATION  \n",
       "232                        nan  ORGANIZATION  \n",
       "242                        nan        PERSON  \n",
       "263                        nan  ORGANIZATION  \n",
       "275                        nan        PERSON  \n",
       "282                        nan        PERSON  \n",
       "314                  1.748 nan  ORGANIZATION  \n",
       "315                        nan  ORGANIZATION  \n",
       "318                        nan        PERSON  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting all rows that are valid\n",
    "\n",
    "final_df = final_df.loc[final_df['Final Label'] != '']\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "859986e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data exported to excel sheet named \"output.xlsx\" successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    # writing to excel file\n",
    "    final_df.to_excel(\"output.xlsx\", sheet_name='Sheet 1', index=False)\n",
    "    print()\n",
    "    print('Data exported to excel sheet named \"output.xlsx\" successfully.')\n",
    "    \n",
    "except Exception:\n",
    "    print('There was an error!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0726d5d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
